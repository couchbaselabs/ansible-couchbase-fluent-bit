#!/usr/bin/env bash

version="1.1.3"

_usage() {
  echo -n "${__script} [OPTION]...

 The Couchbase query logger will retrieve all of the slow queries on the local node only, if it is running the
 query service.  The script should be scheduled on a crontab, the results are filtered based on a duration and
 only results from now to the previous duration will be considered for logging when the script is executed.
 The script writes to stdout and the output can be appended to any log file and rotated using common utilities
 that are widely available such as logrotate.  Run the ${__script} --setup command for more details.

 Options:
  -u, --username          Cluster Admin or RBAC username (default: \$CB_USERNAME or Administrator)
  -p, --password          Cluster Admin or RBAC password (default: \$CB_PASSWORD or password)
  --min-fetches           (optional) The minimum number of fetches to filter the queries on. (default: 0)
  --min-result-count      (optional) The minimum number of results to filter the queries on. (default: 0)
  --min-result-size       (optional) The minimum size of results in bytes to filter the queries on. (default: 0)
  --min-elapsed-time      (optional) The minimum elapsed time to filter the results on. (default: 0)
  -d, --duration          (optional) How far back to look in milliseconds (default: 60000)
  -e, --exclude-fields    (optional) Comma-delimited list of fields to remove from the logged response, for example
                          it maybe useful to eliminate namedArgs, positionalArgs and statement because of PII concerns,
                          possible values are:
                          - clientContextID
                          - elapsedTime
                          - errors
                          - errorCount
                          - namedArgs
                          - node
                          - phaseCounts
                          - phaseOperators
                          - phaseTimes
                          - positionalArgs
                          - querySelectivity
                          - remoteAddr
                          - requestId
                          - requestTime
                          - resultCount
                          - resultSize
                          - scanConsistency
                          - serviceTime
                          - state
                          - statement
                          - statementHash
                          - useCBO
                          - userAgent
                          - users
                          (default: none)
  -r, --port              (optional) The cluster manager port to use (default: 8091)
  -o, --protocol          (optional) The protocol to use (default: http)
  -t, --timeout           (optional) The timeout to use for HTTP requests (default: 5)
  -q, --query-port        (optional) The query port to use (default: 8093)
  --log-level             The log level to to use 0-7 (default: 6)
  --debug                 Shortcut for --log-level 7
  --help                  Display this help and exit
  --version               Output version information and exit
"
}


_setup() {
  echo -n "
  The script will output log messages from the script to stderr and output slow
  query log entries to stdout.  The suggested configuration would be to schedule
  a crontab that executes the script once a minute and redirects the output to a file.

  Example Crontab with Defaults, that logs to a file called /var/log/couchbase/slow-queries.log:

  * * * * * /pathto/query-logger --username admin --password pass >> /var/log/couchbase/slow-queries.log 2>&1

  Example Crontab with flags, that logs to a file called /var/log/couchbase/slow-queries.log:

  * * * * * /pathto/query-logger -u admin -p pass -e statement,namedArgs,positionalArgs >> /var/log/couchbase/slow-queries.log 2>&1

  As the log file can grow in size it is important to make sure that it is rotated, logrotate is a standard tool on
  most installations that runs once per day automatically, and can be called directly.

 Create a new log configuration file for logrotate located in: /etc/logrotate.d/couchbase.conf

  /var/log/couchbase/slow-queries.log {
    daily
    missingok
    notifempty
    rotate 14
    minsize 1M
    size 20M
    compress
    create
  }

  logrotate will run automatically, once a day from /etc/cron.daily, if you want the log file
  to rotate more frequently create an entry in /etc/cron.hourly or a new crontab entry similar
  to the following, logrotate typically must be ran as root:

  0 * * * * logrotate /etc/logrotate.d/couchbase.conf
"
}

# default variables / flags and their optional corresponding environment variables used in the script
USERNAME=${CB_USERNAME:-'Administrator'}
PASSWORD=${CB_PASSWORD:-'password'}
PORT=${PORT:-'8091'}
PROTOCOL=${PROTOCOL:-'http'}
TIMEOUT=${TIMEOUT:-5}
QUERY_PORT=${QUERY_PORT:-'8093'}
DURATION=${DURATION:-60000}
EXCLUDE_FIELDS=${FIELDS:-''}
MIN_FETCHES="0"
MIN_RESULT_COUNT="0"
MIN_RESULT_SIZE="0"
MIN_ELAPSED_TIME="0"
# _options
# -----------------------------------
# Parses CLI options
# -----------------------------------
_options() {
  debug ""
  while [[ $# -gt 0 ]]; do
    case "$1" in
      -r|--port) PORT=${2} && shift 2;;
      -o|--protocol) PROTOCOL=${2} && shift 2;;
      -t|--timeout) TIMEOUT=${2} && shift 2;;
      -d|--duration) DURATION=${2} && shift 2;;
      -q|--query-port) QUERY_PORT=${2} && shift 2;;
      -u|--username) USERNAME=${2} && shift 2;;
      -e|--exclude-fields) EXCLUDE_FIELDS=${2} && shift 2;;
      --min-fetches) MIN_FETCHES=${2} && shift 2;;
      --min-result-count) MIN_RESULT_COUNT=${2} && shift 2;;
      --min-result-size) MIN_RESULT_SIZE=${2} && shift 2;;
      --min-elapsed-time) MIN_ELAPSED_TIME=${2} && shift 2;;
      --setup) _setup >&2; _exit ;;
      -p|--password)
        # if no password was specified prompt for one
        if [ -z "${2:-}" ] || [[ "${2}" == --* ]]; then
          stty -echo # disable keyboard input
          read -p "Password: " -r PASSWORD # prompt the user for the password
          stty echo # enable keyboard input
          echo # new line
          tput cuu1 && tput el # clear the previous line
          shift
        else
          PASSWORD="${2}" # set the passed password
          shift 2
        fi
        ;;
      *)
        error "invalid option: '$1'."
        exit 1
        ;;
    esac
  done
}

# _dependencies
# -----------------------------------
# Ensure script dependencies exist
# -----------------------------------
_dependencies() {
  debug ""
  # check if jq is installed
  if [ "$(command -v jq)" = "" ]; then
    emergency "jq command is required, see (https://stedolan.github.io/jq/download)"
  fi
  # check if sha1sum is installed
  if [ "$(command -v sha1sum)" = "" ]; then
    emergency "sha1sum command is required"
  fi
}

# validate
# -----------------------------------
# Validate Params
# -----------------------------------
_validate() {
  debug ""
  local valid=true
  # validate that there is a username
  if [[ -z "$USERNAME" ]]; then
    warning "The -u/--username argument is required" && valid=false
  fi
  # validate that there is a password
  if [[ -z "$PASSWORD" ]]; then
    warning "The -p/--password argument is required" && valid=false
  fi
  # validate the protocol argument is http/https
  if ! [[ "$PROTOCOL" =~ ^https?$ ]]; then
    warning "The -s/--protocol argument can only be \"http\" or \"https\"" && valid=false
  fi
  # validate the port argument is a number
  if ! [[ "$PORT" =~ ^[1-9][0-9]*$ ]]; then
    warning "The -r/--port argument must be an integer greater than 0" && valid=false
  fi
  # validate the timeout argument is a number
  if ! [[ "$TIMEOUT" =~ ^[1-9][0-9]*$ ]]; then
    warning "The -t/--timeout argument must be an integer greater than 0" && valid=false
  fi
  # validate the log level is between 0-7 argument is a number
  if ! [[ "$LOG_LEVEL" =~ ^[0-7]$ ]]; then
    warning "The -l/--log-level argument must be an integer between 0-7" && valid=false
  fi
  # validate the port argument is a number
  if ! [[ "$QUERY_PORT" =~ ^[1-9][0-9]*$ ]]; then
    warning "The -q/--query-port argument must be an integer greater than 0" && valid=false
  fi
  # validate the duration is a number
  if ! [[ "$DURATION" =~ ^[1-9][0-9]*$ ]]; then
    warning "The -d/--duration argument must be an integer greater than 0" && valid=false
  fi
  # validate the min-fetches is a number
  if ! [[ "$MIN_FETCHES" =~ ^[0-9]+$ ]]; then
    warning "The --min-fetches argument must be an integer greater than 0" && valid=false
  fi
  # validate the min-result-count is a number
  if ! [[ "$MIN_RESULT_COUNT" =~ ^[0-9]+$ ]]; then
    warning "The --min-result-count argument must be an integer greater than 0" && valid=false
  fi
  # validate the min-result-size is a number
  if ! [[ "$MIN_RESULT_SIZE" =~ ^[0-9]+$ ]]; then
    warning "The --min-result-size argument must be an integer greater than 0" && valid=false
  fi
  # validate the min-elapsed-time is a number
  if ! [[ "$MIN_ELAPSED_TIME" =~ ^[0-9]+$ ]]; then
    warning "The --min-elapsed-time argument must be an integer greater than 0" && valid=false
  fi
  # if there are errors
  if ( ! $valid ); then
    exit 1
  fi
}

# main
# -----------------------------------
# Main function
# -----------------------------------
main() {
  # log the invocation command and arguments
  debug "
  invocation:
    $__invocation
  arguments:
    username: $USERNAME
    password: ********
    port: $PORT
    protocol: $PROTOCOL
    timeout: $TIMEOUT
    query_port: $QUERY_PORT
    exclude_fields: $EXCLUDE_FIELDS
    duration: $DURATION
    min_fetches: $MIN_FETCHES
    min_result_count: $MIN_RESULT_COUNT
    min_result_size: $MIN_RESULT_SIZE
    min_elapsed_time: $MIN_ELAPSED_TIME"
  # confirm the local node is a query node
  local is_query_node
  is_query_node=$(isQueryNode)

  if [ "$is_query_node" == "true" ]; then
    # build the slow query n1ql statement to be used
    local n1ql
    n1ql=$(getSlowQueryStatement)
    # build the params
    local params="\$duration=$DURATION&\$minFetches=$MIN_FETCHES&\$minResultCount=$MIN_RESULT_COUNT&\$minResultSize=$MIN_RESULT_SIZE&\$minElapsedTime=$MIN_ELAPSED_TIME"
    # execute the query
    local results
    results=$(executeN1ql "${n1ql//$'\n'/}" "$params")
    debug "Slow Queries Found: $(echo "${results}" | jq -r '. | length')"
    # loop over each one of the results
    local row
    for row in $(echo "${results}" | jq -r '.[] | @base64'); do
      # local function to parse each row
      _jq() {
       echo "${row}" | base64 --decode | jq -r --arg statement_hash "${2:-''}" --arg exclude_fields "$EXCLUDE_FIELDS" "${1}"
      }
      local statement_hash
      statement_hash=$(_jq '.statement' | sha1sum | awk '{ print $1 }')
      # output the logged slow query
      # shellcheck disable=SC2016
      _jq '
        . as $org |
        $exclude_fields | ascii_downcase | split(",") as $exclude_fields |
        $org.requestTime +
        (
          if ($org.errorCount > 0) then
            " [ERROR] "
          else
            " [INFO] "
          end
        ) +  (
          $org + { "statementHash": $statement_hash } | reduce to_entries[] as $item ({};
            if ($exclude_fields | index($item.key | ascii_downcase) | not) then
              .[$item.key] = $item.value
            else
              .
            end
          ) | tostring
        )
      ' "$statement_hash"
    done
  fi
}

# getSlowQueryStatement
# -----------------------------------
# Build a N1QL statement to identify the slow queries
# -----------------------------------
getSlowQueryStatement() {
  debug ""
  # build a n1ql statement to query system:completed_requests,
  local n1ql="
    PREPARE
    SELECT RAW OBJECT_CONCAT(
      OBJECT_REMOVE(OBJECT_REMOVE(cr, 'statement'), 'preparedText'),
      {
        cost,
        requestTimeMs,
        elapsedTimeMs,
        serviceTimeMs,
        queueTime,
        queueTimeMs,
        querySelectivityPercent,
        \"statement\": stmt,
        \"bucket\": source[0],
        \"scope\": IFMISSINGORNULL(source[1], \"_default\"),
        \"collection\": IFMISSINGORNULL(source[2], \"_default\")
      }
    )
    FROM system:completed_requests AS cr
    LET requestTimeMs = STR_TO_MILLIS(STR_TO_UTC(REPLACE(REGEX_REPLACE(REPLACE(REPLACE(REGEX_REPLACE(cr.requestTime, \" [A-Z]{3}$\", ''), ' -', '-'), ' +', '+'), ':?00$', ':00'), ' ', 'T'))),
      serviceTimeMs = ROUND(STR_TO_DURATION(cr.serviceTime) / 1e6),
      elapsedTimeMs = ROUND(STR_TO_DURATION(cr.elapsedTime) / 1e6),
      queueTime = DURATION_TO_STR(STR_TO_DURATION(cr.elapsedTime) - STR_TO_DURATION(cr.serviceTime)),
      queueTimeMs = ROUND(
        (STR_TO_DURATION(cr.elapsedTime) - STR_TO_DURATION(cr.serviceTime)) / 1e6
      , 3),
      querySelectivityPercent = ROUND(IFNULL(
        (
          cr.resultCount /
          IFMISSING(cr.phaseCounts.\`indexScan\`, 0)
        ) * 100,
      0), 2),
      cost = ARRAY_SUM(OBJECT_VALUES(IFMISSINGORNULL(phaseCounts, {}))),
      stmt = IFMISSING(cr.preparedText, cr.statement),
      source = SPLIT(
        REGEX_REPLACE(
          IFMISSINGORNULL(
            ARRAY_REVERSE(
              REGEXP_MATCHES(
                stmt,
                \"(([Ii][Nn]|[Uu][Pp])[Ss][Ee][Rr][Tt]\\\\s+[Ii][Nn][Tt][Oo]|[Uu][Pp][Dd][Aa][Tt][Ee]|[Ff][Rr][Oo][Mm])\\\\s+\`?[^ ]+\"
              )
            )[0],
            \"Unknown\"
          ),
          \"^[^ ]+\\\\s+\`?|\`?(\\\\s|\\\\n)+.+$|\`$\", \"\"),
        \".\"
      )
    WHERE cr.node = NODE_NAME()
      AND IFMISSINGORNULL(cr.clientContextID, '') NOT LIKE 'INTERNAL-%'
      AND UPPER(IFMISSING(cr.preparedText, cr.statement)) NOT LIKE 'INFER %'
      AND UPPER(IFMISSING(cr.preparedText, cr.statement)) NOT LIKE 'ADVISE %'
      AND UPPER(IFMISSING(cr.preparedText, cr.statement)) NOT LIKE '%CREATE INDEX%'
      AND UPPER(IFMISSING(cr.preparedText, cr.statement)) NOT LIKE '%ALTER INDEX%'
      AND UPPER(IFMISSING(cr.preparedText, cr.statement)) NOT LIKE '% SYSTEM:%'
      AND requestTimeMs >= ROUND(STR_TO_MILLIS(NOW_UTC()), 0) - 60000
    ORDER BY requestTimeMs ASC"

  echo "$n1ql"
}

# executeN1ql
# -----------------------------------
# Execute a N1QL statement
# -----------------------------------
# shellcheck disable=SC2001
executeN1ql() {
  local statement="${1}"
  local params="${2}"
  debug "
    statement: $statement
    params: $params"
  # call the nodes endpoint
  local url="$PROTOCOL://localhost:$QUERY_PORT/query/service?auto_execute=true&$params"
  debug "url: $url"
  local http_response
  http_response=$(curl \
    --insecure \
    --user "$USERNAME:$PASSWORD" \
    --silent \
    --data-urlencode "statement=$statement" \
    --connect-timeout "$TIMEOUT" \
    --max-time "$TIMEOUT" \
    --write-out "HTTPSTATUS:%{http_code}" \
    "$url")
  local http_body
  http_body=$(echo "$http_response" | sed -e 's/HTTPSTATUS\:.*//g')
  local http_status
  http_status=$(echo "$http_response" | tr -d '\n' | sed -e 's/.*HTTPSTATUS://')
  # inspect the response code
  if [ "$http_status" -eq "200" ]; then
    # parse the response, append the indexes from the cluster to the global indexes variable
    echo "$http_body" | jq --raw-output --compact-output \
      '.results'
  else
    error "Error contacting the query_node: $PROTOCOL://localhost:$QUERY_PORT"
    debug "$http_body"
    exit 1
  fi
}

# isQueryNode
# -----------------------------------
# Determines if the local node is a query node or not
# -----------------------------------
# shellcheck disable=SC2001
isQueryNode() {
  debug ""
  local is_query_node
  # call the nodes endpoint
  local url="$PROTOCOL://localhost:$PORT/pools/nodes"
  debug "url: $url"
  local http_response
  http_response=$(curl \
    --insecure \
    --user "$USERNAME:$PASSWORD" \
    --silent \
    --connect-timeout "$TIMEOUT" \
    --max-time "$TIMEOUT" \
    --request GET \
    --write-out "HTTPSTATUS:%{http_code}" \
    "$url")
  local http_body
  http_body=$(echo "$http_response" | sed -e 's/HTTPSTATUS\:.*//g')
  local http_status
  http_status=$(echo "$http_response" | tr -d '\n' | sed -e 's/.*HTTPSTATUS://')
  # inspect the response code
  if [ "$http_status" -eq "200" ]; then
    # parse the response, append the indexes from the cluster to the global indexes variable
    is_query_node=$(echo "$http_body" | jq --raw-output --compact-output \
      --argjson input "$http_body" \
      '.nodes[] | select(.thisNode//false == true and .clusterMembership == "active" and .status == "healthy") | .services | contains(["n1ql"])')
  else
    error "Error contacting http://localhost:8091/pools/default"
    debug "$http_body"
    exit 1
  fi

  debug "$is_query_node"
  echo "$is_query_node"
}


# ******************************************************************************************************
# *********************                DO NOT EDIT BELOW THIS LINE                **********************
# ******************************************************************************************************
# Template inspired by:
#  - https://github.com/oxyc/bash-boilerplate/blob/master/script.sh
#  - https://github.com/kvz/bash3boilerplate/blob/master/example.sh

set -o errexit # Exit on error. Append '||true' when you run the script if you expect an error.
set -o errtrace # Exit on error inside any functions or subshells.
set -o pipefail # Exit on piping, bash will remember & return the highest exitcode in a chain of pipes.
set -o nounset # Exit when undeclared variables are used

# magic variables for use within the script
__dir="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)" # the directory the script is being executed in
__script_path="${__dir}/$(basename "${BASH_SOURCE[0]}")" # the full path to the script
__script="$(basename "${__script_path}")" # the name of the script including the extension
__script_name="$(basename "${__script_path}" .sh)" # the name of the script without the extension
# shellcheck disable=SC2015
__invocation="$(printf %q "${__script_path}")$( (($#)) && printf ' %q' "$@" || true )" # the invocating command and options passed to the script at execution time

# Set Temp Directory
# -----------------------------------
# Create temp directory with three random numbers and the process ID
# in the name.  This directory is removed automatically at exit.
# -----------------------------------
tmp_dir="/tmp/${__script_name}.$RANDOM.$RANDOM.$RANDOM.$$"
(umask 077 && mkdir "${tmp_dir}") || {
  error "Could not create temporary directory! Exiting." && exit 1
}

# _cleanup
# -----------------------------------
# Remove any tmp files, if any
# -----------------------------------
_cleanup() {
  if [ -d "${tmp_dir}" ]; then
    rm -r "${tmp_dir}"
  fi
}

LOG_LEVEL=${LOG_LEVEL:=6} # 7 = debug -> 0 = emergency
NO_COLOR="${NO_COLOR:-}"
TRACE="0"

# _log
# -----------------------------------
# Handles all logging, all log messages are output to stderr so stdout can still be piped
#   Example: _log "info" "Some message"
# -----------------------------------
# shellcheck disable=SC2034
_log () {
  local log_level="${1}" # first option is the level, the rest is the message
  shift
  local color_success="\\x1b[32m"
  local color_debug="\\x1b[36m"
  local color_info="\\x1b[90m"
  local color_notice="\\x1b[34m"
  local color_warning="\\x1b[33m"
  local color_error="\\x1b[31m"
  local color_critical="\\x1b[1;31m"
  local color_alert="\\x1b[1;33;41m"
  local color_emergency="\\x1b[1;4;5;33;41m"
  local colorvar="color_${log_level}"
  local color="${!colorvar:-${color_error}}"
  local color_reset="\\x1b[0m"

  # If no color is set or a non-recognized terminal is used don't use colors
  if [[ "${NO_COLOR:-}" = "true" ]] || { [[ "${TERM:-}" != "xterm"* ]] && [[ "${TERM:-}" != "screen"* ]]; } || [[ ! -t 2 ]]; then
    if [[ "${NO_COLOR:-}" != "false" ]]; then
      color="";
      color_reset="";
    fi
  fi

  # all remaining arguments are to be printed
  local log_line=""

  while IFS=$'\n' read -r log_line; do
    echo -e "$(date +"%Y-%m-%d %H:%M:%S %Z") ${color}[${log_level}]${color_reset} ${log_line}" 1>&2
  done <<< "${@:-}"
}

# emergency
# -----------------------------------
# Handles emergency logging
# -----------------------------------
emergency() {
  _log emergency "${@}"; exit 1;
}

# success
# -----------------------------------
# Handles success logging
# -----------------------------------
success() {
  _log success "${@}"; true;
}

# alert
# -----------------------------------
# Handles alert logging
# -----------------------------------
alert() {
  [[ "${LOG_LEVEL:-0}" -ge 1 ]] && _log alert "${@}";
  true;
}

# critical
# -----------------------------------
# Handles critical logging
# -----------------------------------
critical() {
  [[ "${LOG_LEVEL:-0}" -ge 2 ]] && _log critical "${@}";
  true;
}

# error
# -----------------------------------
# Handles error logging
# -----------------------------------
error() {
  [[ "${LOG_LEVEL:-0}" -ge 3 ]] && _log error "${@}";
  true;
}

# warning
# -----------------------------------
# Handles warning logging
# -----------------------------------
warning() {
  [[ "${LOG_LEVEL:-0}" -ge 4 ]] && _log warning "${@}";
  true;
}

# notice
# -----------------------------------
# Handles notice logging
# -----------------------------------
notice() {
  [[ "${LOG_LEVEL:-0}" -ge 5 ]] && _log notice "${@}";
  true;
}

# info
# -----------------------------------
# Handles info logging
# -----------------------------------
info() {
  [[ "${LOG_LEVEL:-0}" -ge 6 ]] && _log info "${@}";
  true;
}

# debug
# -----------------------------------
# Handles debug logging and prepends the name of the that called debug in front of the message
# -----------------------------------
debug() {
  [[ "${LOG_LEVEL:-0}" -ge 7 ]] && _log debug "${FUNCNAME[1]}() ${*}";
  true;
}

# _exit
# -----------------------------------
# Non destructive exit for when script exits naturally.
# -----------------------------------
_exit() {
  _cleanup
  trap - INT TERM EXIT
  exit
}

# _error_report
# -----------------------------------
# Any actions that should be taken if the script is prematurely exited.
# -----------------------------------
_error_report() {
  _cleanup
  error "Error in ${__script} in ${1} on line ${2}"
  exit 1
}

# trap bad exits with custom _trap function
trap '_error_report "${FUNCNAME:-.}" ${LINENO}' ERR

# Set IFS to preferred implementation
IFS=$'\n\t'

# Iterate over options breaking --foo=bar into --foo bar, and handle common arguments like --debug, --log-level, --no-color
unset options
while (($#)); do
  case $1 in
    # If option is of type --foo=bar
    --?*=*) options+=("${1%%=*}" "${1#*=}") ;;
    --help) _usage >&2; _exit ;;
    --version) echo "${__script_name} ${version}"; _exit ;;
    --log-level) LOG_LEVEL=${2} && shift ;;
    --no-color) NO_COLOR=true ;;
    --debug) LOG_LEVEL="7" ;;
    --trace)
      TRACE="1"
      LOG_LEVEL="7"
    ;;
    # add --endopts for --
    --) options+=(--endopts) ;;
    # Otherwise, nothing special
    *) options+=("$1") ;;
  esac
  shift
done

if [ "${options:-}" != "" ]; then
  set -- "${options[@]}"
  unset options
fi

# parse the options
_options "$@"

# if trace has been set to 1 via the --trace argument enable tracing after the options have been parsed
if [[ "${TRACE}" == "1" ]]
then
  set -o xtrace
fi

# validate the options
_validate

# check dependencies
_dependencies

# call the main function
main

# cleanly exit
_exit
